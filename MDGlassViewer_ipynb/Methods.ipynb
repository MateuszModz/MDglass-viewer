{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b32151e6-9e48-428c-920c-e69d23770d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lammps_logfile\n",
    "import scipy\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk\n",
    "import PySimpleGUI as sg\n",
    "import numpy as np\n",
    "import PySimpleGUI as sg\n",
    "import matplotlib.widgets as wg\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from ase.io.lammpsrun import read_lammps_dump_text\n",
    "\n",
    "rdf_dict = {}\n",
    "view_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17501886-5481-44f4-992f-72a6f24e7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method used to load log files. It takes the path of the file and returns log and units.\n",
    "# Log contains all the data and keywords that can be retrieved respectfully with\n",
    "# log.get(keyword, simulation_number) and log.get_keywords(). Units contains unit types\n",
    "# (e.g. 'metal') of simulations in file.\n",
    "def read_log_file(file):\n",
    "    log = lammps_logfile.File(file)\n",
    "    units = []\n",
    "    file.seek(0)\n",
    "    for line in file:\n",
    "        # Works for log format, usually a single simulation.\n",
    "        if 'units' in line:\n",
    "            line = line.partition(' ')[2]\n",
    "            line = line.rstrip()\n",
    "            units.append(line)\n",
    "        # Works for out format, usually multiple simulations.\n",
    "        if 'Unit style' in line:\n",
    "            line = line.partition(': ')[2]\n",
    "            line = line.rstrip()\n",
    "            units.append(line)\n",
    "    return log, units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26bcd17b-af3d-43ab-b027-ce58742f2f84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Meethod used to load rdf LAMMPS files.\n",
    "def read_RDF_file(file, win_id):\n",
    "    if win_id not in list(rdf_dict.keys()):\n",
    "        rdf_dict[win_id] = {}\n",
    "    data_dict = rdf_dict[win_id]\n",
    "    try:\n",
    "        x = []\n",
    "        col_number = []\n",
    "        missing_col_keys = []\n",
    "        redundant_col_keys = []\n",
    "        for line in file:\n",
    "            if not line.startswith(\"#\"):\n",
    "                t = line.strip('\\n').split()\n",
    "                t = [float(x) for x in t]\n",
    "                if len(t) == 2:\n",
    "                    key, N = str(int(t[0])), t[1]\n",
    "                else:\n",
    "                    length = len(t)\n",
    "                    col_number.append(length)\n",
    "                    if length == col_number[0]:\n",
    "                        x.append(t)\n",
    "                    elif length < col_number[0]:\n",
    "                        r = col_number[0]-length\n",
    "                        missing_col_keys.append(key)\n",
    "                        [t.append(0.0) for i in range(r)]\n",
    "                        x.append(t)\n",
    "                    else:\n",
    "                        r = length-col_number[0]\n",
    "                        redundant_col_keys.append(key)\n",
    "                        [t.pop(-i) for i in range(1, r+1)]\n",
    "                        x.append(t)\n",
    "\n",
    "                if len(x) == N:\n",
    "                    data_dict.update({key: x})\n",
    "                    x = []\n",
    "\n",
    "        if len(missing_col_keys) > 0:\n",
    "            sg.popup_ok(\n",
    "                f'A mismatch in number of columns occurred in timestep(s)\\n{\", \".join(missing_col_keys)}\\nwhile attempting to load\\n{file.name}.\\nMissing rows were filled with 0.0.', title='Warning')\n",
    "        if len(redundant_col_keys) > 0:\n",
    "            sg.popup_ok(\n",
    "                f'A mismatch in number of columns occurred in timestep(s)\\n{\", \".join(redundant_col_keys)}\\nwhile attempting to load\\n{file.name}.\\nRedundant rows were removed.', title='Warning')\n",
    "\n",
    "        rdf_dict[win_id] = data_dict\n",
    "        return rdf_dict, col_number[0]\n",
    "    except ValueError:\n",
    "        sg.popup_ok(\n",
    "            f'An error occurred while attempting to load\\n{file.name}.', title='Error')\n",
    "    except TypeError:\n",
    "        sg.popup_ok(\n",
    "            f'An error occurred while attempting to load\\n{file.name}.', title='Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386d6324-a32b-4f22-8b89-6e9d467d88ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1']\n"
     ]
    }
   ],
   "source": [
    "def read_dump_file(file, win_id):\n",
    "    try:\n",
    "        view_dict[win_id] = {}\n",
    "        timesteps = []\n",
    "        for line in file:\n",
    "            if 'ITEM: TIMESTEP' in line:\n",
    "                timesteps.append(file.readline().strip())\n",
    "\n",
    "        for n in range(len(timesteps)):\n",
    "            file.seek(0)\n",
    "            key = timesteps[n]\n",
    "            view_dict[win_id][key] = read_lammps_dump_text(file, index=n)\n",
    "        number_of_atoms = len(view_dict[win_id][key])\n",
    "        if number_of_atoms > 1000:\n",
    "            sg.popup_ok(\n",
    "                f'Dump file\\n{file.name}\\ncontains more than 1000 atoms. A smaller section of the simulation box will be shown fot the sake of clarity and performance.', title='Warning')\n",
    "        return view_dict\n",
    "    except ValueError:\n",
    "        sg.popup_ok(\n",
    "            f'An error occurred while attempting to load\\n{file.name}.', title='Error')\n",
    "    except TypeError:\n",
    "        sg.popup_ok(\n",
    "            f'An error occurred while attempting to load\\n{file.name}.', title='Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40774e11-59b9-4537-9e1c-d3679aa52564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_fit(x, y, lower_bound_id=0, higher_bound_id=0):\n",
    "    if higher_bound_id != 0 and higher_bound_id > lower_bound_id:\n",
    "        if higher_bound_id > x.size:\n",
    "            higher_bound_id = x.size\n",
    "        x_new = x[lower_bound_id:higher_bound_id]\n",
    "        y_new = y[lower_bound_id:higher_bound_id]\n",
    "    else:\n",
    "        x_new = x\n",
    "        y_new = y\n",
    "    a, b, c, d, e = scipy.stats.linregress(x_new, y_new)\n",
    "\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b303a7fc-e945-4f71-94ca-8e583b53561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "units_dict = {'metal': {'Step': '', 'Time': 'ps', 'TotEng': 'eV', 'Temp': 'K', 'Volume': 'A^3', 'Density': 'g/cm^3', 'Press': 'bar', 'Ndanger': '', 'PotEng': 'eV', 'KinEng': 'eV', 'Enthalpy': 'eV'},\n",
    "              'real': {'Step': '', 'Time': 'fs', 'TotEng': 'kcal/mol', 'Temp': 'K', 'Volume': 'A^3', 'Density': 'g/cm^3', 'Press': 'atm', 'Ndanger': '', 'PotEng': 'kcal/mol', 'KinEng': 'kcal/mol', 'Enthalpy': 'kcal/mol'},\n",
    "              'SI': {'Step': '', 'Time': 's', 'TotEng': 'J', 'Temp': 'K', 'Volume': 'm^3', 'Density': 'kg/m^3', 'Press': 'Pa', 'Ndanger': '', 'PotEng': 'J', 'KinEng': 'J', 'Enthalpy': 'J'},\n",
    "              'LJ': {'Step': '', 'Time': '', 'TotEng': '', 'Temp': '', 'Volume': '', 'Density': '', 'Press': '', 'Ndanger': '', 'PotEng': '', 'KinEng': '', 'Enthalpy': ''}}\n",
    "\n",
    "\n",
    "def units(units_type, x):\n",
    "    return units_dict[units_type][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0889fbfb-a964-4347-95f9-86e61938c57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006175"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formats a number to sig significant figures, default 4\n",
    "def format_number(number, sig=4):\n",
    "    str_number = str(number)\n",
    "    str_number = str_number.split('.')\n",
    "    zeros = 0\n",
    "    for char in list(str_number[1]):\n",
    "        if str_number[0] == '0' and char == '0':\n",
    "            zeros+=1\n",
    "    n = sig + zeros\n",
    "    formatted_number = format(number, f'.{n}f')\n",
    "    return float(formatted_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26d129ec-6b9d-4faf-a05f-f211c3e90944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intersection(a1, b1, a2, b2):\n",
    "    x_intersection = (b2 - b1) / (a1 - a2)\n",
    "    y_intersection = a1 * x_intersection + b1\n",
    "    return x_intersection, y_intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e85165f8-824b-477e-8639-74e0da1e88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_point(x, y, x0, y0):\n",
    "    min_distance = float('inf')\n",
    "    closest_point_index = -1\n",
    "    x_norm = abs(np.max(x)-np.min(x))\n",
    "    y_norm = abs(np.max(y)-np.min(y))\n",
    "    x00 = x0 / x_norm\n",
    "    y00 = y0 / y_norm\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        xp = x[i] / x_norm\n",
    "        yp = y[i] / y_norm\n",
    "        distance = np.sqrt((xp - x00)**2 + (yp - y00)**2)\n",
    "\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_point_index = i\n",
    "\n",
    "    x_res = x[closest_point_index]\n",
    "    y_res = y[closest_point_index]\n",
    "\n",
    "    return x_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0816332-67c4-45a8-aaab-15fa0eb57e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_value(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13ed0b-fe9b-4d53-993e-f523f979c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_headings(table, headings):\n",
    "    COL_HEADINGS = ['Line', 'Slope', 'Intercept', 'Boundry 1', 'Boundry 2']\n",
    "    for cid, text in zip(COL_HEADINGS, headings):\n",
    "        table.heading(cid, text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95cd4abf-27e2-49ae-a571-1e2e052cb008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method used to update comboboxes in main window upon loading new file.\n",
    "def update_combos_main(keywords, n, window, tab_id):\n",
    "    combo_n = np.arange(1, n+1).tolist()\n",
    "    for i in range(2, 5):\n",
    "        window[f'combo_n{i}_{tab_id}'].update(\n",
    "            value=combo_n[0], values=combo_n)\n",
    "        window[f'combo_x{i}_{tab_id}'].update(\n",
    "            value=keywords[0], values=keywords)\n",
    "        window[f'combo_y{i}_{tab_id}'].update(\n",
    "            value=keywords[1], values=keywords)\n",
    "\n",
    "    if 'Temp' and 'TotEng' in keywords:\n",
    "        window[f'combo_n1_{tab_id}'].update(\n",
    "            value=combo_n[0], values=combo_n)\n",
    "        window[f'combo_x1_{tab_id}'].update(\n",
    "            value='Temp', values=keywords)\n",
    "        window[f'combo_y1_{tab_id}'].update(\n",
    "            value='TotEng', values=keywords)\n",
    "\n",
    "    else:\n",
    "        window[f'combo_n1_{tab_id}'].update(\n",
    "            value=combo_n[0], values=combo_n)\n",
    "        window[f'combo_x1_{tab_id}'].update(\n",
    "            value=keywords[0], values=keywords)\n",
    "        window[f'combo_y1_{tab_id}'].update(\n",
    "            value=keywords[1], values=keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c74feb-0ae2-4d99-8697-5ef48ca268ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method used to update comboboxes in analyze windows.\n",
    "def update_combos_analyze(analyze_window, values, tab_id, combo_xy, n):\n",
    "    combo_n = np.arange(1, n+1).tolist()\n",
    "\n",
    "    for i in ('fit', 'rdf', 'view'):\n",
    "        analyze_window[f'combo_x{i}_{tab_id}'].update(\n",
    "            value=values[f'combo_x1_{tab_id}'], values=combo_xy)\n",
    "\n",
    "        analyze_window[f'combo_y{i}_{tab_id}'].update(\n",
    "            value=values[f'combo_y1_{tab_id}'], values=combo_xy)\n",
    "\n",
    "        analyze_window[f'combo_n{i}_{tab_id}'].update(\n",
    "            value=values[f'combo_n1_{tab_id}'], values=combo_n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
